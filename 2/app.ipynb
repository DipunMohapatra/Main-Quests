{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d24fb9e-f4db-46e5-8422-df7ccb1c688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import nltk\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from transformers import pipeline\n",
    "import concurrent.futures  # For parallel processing\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize the sentiment analysis model once at the start\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Load sentiment data\n",
    "@st.cache_data\n",
    "def load_sentiment_data(uploaded_file) -> pd.DataFrame:\n",
    "    data = pd.read_excel(uploaded_file)\n",
    "    return data\n",
    "\n",
    "# Improved Sentiment analysis and visualization\n",
    "def analyze_sentiments(df, text_column):\n",
    "    # Convert the specified column to string type\n",
    "    df[text_column] = df[text_column].astype(str)\n",
    "\n",
    "    # Initialize NLTK sentiment analyzer\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # Compute sentiment scores using NLTK VADER\n",
    "    df['nltk_sentiment_scores'] = df[text_column].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "    df['nltk_sentiment_category'] = df['nltk_sentiment_scores'].apply(\n",
    "        lambda x: 'Positive' if x > 0.05 else ('Negative' if x < -0.05 else 'Neutral')\n",
    "    )\n",
    "\n",
    "    # Compute sentiment scores using a transformer-based model (batch processing)\n",
    "    texts = df[text_column].tolist()\n",
    "\n",
    "    # Use batch processing and parallelization\n",
    "    transformer_results = []\n",
    "    batch_size = 16  # You can adjust this based on your hardware capabilities\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(sentiment_pipeline, texts[i:i + batch_size]) for i in range(0, len(texts), batch_size)]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            transformer_results.extend(future.result())\n",
    "\n",
    "    # Extract sentiment label and score\n",
    "    df['transformer_sentiment_label'] = [result['label'] for result in transformer_results]\n",
    "    df['transformer_sentiment_score'] = [result['score'] for result in transformer_results]\n",
    "\n",
    "    # Map transformer sentiment labels to categories\n",
    "    df['transformer_sentiment_category'] = df['transformer_sentiment_label'].apply(\n",
    "        lambda x: 'Positive' if x == 'POSITIVE' else ('Negative' if x == 'NEGATIVE' else 'Neutral')\n",
    "    )\n",
    "\n",
    "    # Compare and decide final sentiment category based on the most confident prediction\n",
    "    df['final_sentiment_category'] = np.where(\n",
    "        df['transformer_sentiment_score'] > 0.6,  # Threshold for confident prediction\n",
    "        df['transformer_sentiment_category'],\n",
    "        df['nltk_sentiment_category']\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "def plot_sentiment_pie_chart(df):\n",
    "    # Count the number of occurrences of each sentiment category\n",
    "    sentiment_counts = df['final_sentiment_category'].value_counts()\n",
    "    \n",
    "    # Create a pie chart\n",
    "    fig = go.Figure(data=[go.Pie(labels=sentiment_counts.index, \n",
    "                                 values=sentiment_counts.values,\n",
    "                                 hoverinfo='label+percent',\n",
    "                                 textinfo='value+percent')])\n",
    "    fig.update_traces(marker=dict(colors=['#00CC96', '#EF553B', '#636EFA']))\n",
    "    fig.update_layout(title=\"Sentiment Distribution\", template=\"plotly_dark\")\n",
    "    \n",
    "    st.plotly_chart(fig)\n",
    "\n",
    "def display_comments_by_sentiment(df, sentiment_type, text_column):\n",
    "    filtered_df = df[df['final_sentiment_category'] == sentiment_type]\n",
    "    st.subheader(f\"{sentiment_type} Comments\")\n",
    "    if not filtered_df.empty:\n",
    "        st.write(filtered_df[[text_column, 'nltk_sentiment_scores', 'transformer_sentiment_score']].reset_index(drop=True))\n",
    "    else:\n",
    "        st.write(\"No comments found.\")\n",
    "\n",
    "def plot_top_words(df, text_column, num_words=10):\n",
    "    vectorizer = CountVectorizer(stop_words='english')  # Use 'english' for built-in stop words\n",
    "    word_counts = vectorizer.fit_transform(df[text_column].dropna())\n",
    "    \n",
    "    sum_words = word_counts.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    top_words_df = pd.DataFrame(words_freq[:num_words], columns=['Word', 'Frequency'])\n",
    "\n",
    "    # Plot bar chart using Plotly Express\n",
    "    fig = px.bar(top_words_df, x='Frequency', y='Word', orientation='h', \n",
    "                 title=f'Top {num_words} Occurring Words',\n",
    "                 template=\"plotly_dark\")\n",
    "    st.plotly_chart(fig)\n",
    "\n",
    "def plot_top_bigrams(df, text_column, num_bigrams=10):\n",
    "    vectorizer = CountVectorizer(stop_words='english', ngram_range=(2, 2))  # Use 'english' for built-in stop words\n",
    "    bigram_counts = vectorizer.fit_transform(df[text_column].dropna())\n",
    "    \n",
    "    sum_bigrams = bigram_counts.sum(axis=0)\n",
    "    bigrams_freq = [(bigram, sum_bigrams[0, idx]) for bigram, idx in vectorizer.vocabulary_.items()]\n",
    "    bigrams_freq = sorted(bigrams_freq, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    top_bigrams_df = pd.DataFrame(bigrams_freq[:num_bigrams], columns=['Bigram', 'Frequency'])\n",
    "\n",
    "    # Plot bar chart using Plotly Express\n",
    "    fig = px.bar(top_bigrams_df, x='Frequency', y='Bigram', orientation='h', \n",
    "                 title=f'Top {num_bigrams} Occurring Bigrams',\n",
    "                 template=\"plotly_dark\")\n",
    "    st.plotly_chart(fig)\n",
    "\n",
    "def generate_wordcloud(text, title):\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    wordcloud = WordCloud(stopwords=stop_words, background_color='black', colormap='plasma').generate(' '.join(text))\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title, color='white')\n",
    "    st.pyplot(plt)\n",
    "\n",
    "def identify_themes(df, text_column, num_topics=3):\n",
    "    vectorizer = CountVectorizer(stop_words='english')  # Use 'english' for built-in stop words\n",
    "    text_data = vectorizer.fit_transform(df[text_column])\n",
    "    \n",
    "    # Use LDA to identify themes\n",
    "    lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "    lda.fit(text_data)\n",
    "    \n",
    "    # Display the themes\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "    themes = []\n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        top_features_ind = topic.argsort()[:-6:-1]\n",
    "        top_features = [words[i] for i in top_features_ind]\n",
    "        themes.append(\" \".join(top_features))\n",
    "    \n",
    "    return themes\n",
    "\n",
    "# Main app\n",
    "def main():\n",
    "    st.set_page_config(\n",
    "        page_title=\"Sentiment Analysis Dashboard\",\n",
    "        page_icon=\"ðŸ˜Š\",\n",
    "        layout=\"wide\",\n",
    "    )\n",
    "\n",
    "    st.title(\"ðŸ˜Š Sentiment Analysis Dashboard\")\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "        <style>\n",
    "        .stApp {\n",
    "            background-color: black;\n",
    "            font-family: 'Open Sans', sans-serif;\n",
    "        }\n",
    "        .css-1lcbmhc, .css-1y4p8pa {\n",
    "            background-color: #1e1e1e;\n",
    "            color: white;\n",
    "        }\n",
    "        .sidebar .sidebar-content {\n",
    "            background-color: #1e1e1e;\n",
    "        }\n",
    "        h1, h2, h3, h4, h5, h6, p, label, .stTextInput label {\n",
    "            color: white;\n",
    "        }\n",
    "        .stTabs [role=\"tablist\"] .tab-label {\n",
    "            color: white !important;\n",
    "        }\n",
    "        .stTabs [role=\"tablist\"] .st-tab:hover {\n",
    "            background-color: #333333;\n",
    "        }\n",
    "        .stTabs [role=\"tablist\"] .st-tab[data-selected=\"true\"] {\n",
    "            border-bottom: 2px solid #2196f3 !important;\n",
    "            color: #2196f3 !important;\n",
    "        }\n",
    "        .st-infobox {\n",
    "            background-color: #333333;\n",
    "            border: 1px solid #555555;\n",
    "        }\n",
    "        </style>\n",
    "        \"\"\",\n",
    "        unsafe_allow_html=True\n",
    "    )\n",
    "    \n",
    "    st.sidebar.title(\"Navigation\")\n",
    "    st.sidebar.markdown(\"Upload your dataset and select a column for sentiment analysis.\")\n",
    "\n",
    "    # File uploader for sentiment analysis\n",
    "    uploaded_sentiment_file = st.file_uploader(\"Upload your Excel dataset for Sentiment Analysis:\", type=[\"xlsx\"])\n",
    "    \n",
    "    if uploaded_sentiment_file:\n",
    "        df = load_sentiment_data(uploaded_sentiment_file)\n",
    "        st.write(\"Data Preview:\")\n",
    "        st.dataframe(df.head())\n",
    "\n",
    "        # Select a column for analysis\n",
    "        column_options = df.columns.tolist()\n",
    "        selected_column = st.selectbox(\"Select a column for analysis:\", column_options)\n",
    "\n",
    "        if selected_column:\n",
    "            if np.issubdtype(df[selected_column].dtype, np.number):\n",
    "                st.error(\"Selected column is numeric. Please select a text column for sentiment analysis.\")\n",
    "            else:\n",
    "                # Perform sentiment analysis if column is of string type\n",
    "                df = analyze_sentiments(df, selected_column)\n",
    "\n",
    "                # Visualize sentiment distribution and comments\n",
    "                plot_sentiment_pie_chart(df)\n",
    "\n",
    "                # Display comments by sentiment\n",
    "                sentiment_choice = st.radio(\"Select sentiment to view comments:\", ['Positive', 'Negative', 'Neutral'])\n",
    "                display_comments_by_sentiment(df, sentiment_choice, selected_column)\n",
    "\n",
    "                # Word Cloud\n",
    "                st.subheader(\"Word Cloud\")\n",
    "                generate_wordcloud(df[selected_column].dropna(), \"Word Cloud of Comments\")\n",
    "\n",
    "                # Top Words\n",
    "                st.subheader(\"Top Words\")\n",
    "                plot_top_words(df, selected_column)\n",
    "\n",
    "                # Top Bigrams\n",
    "                st.subheader(\"Top Bigrams\")\n",
    "                plot_top_bigrams(df, selected_column)\n",
    "\n",
    "                # Thematic identification\n",
    "                st.subheader(\"Thematic Identification\")\n",
    "                themes = identify_themes(df, selected_column)\n",
    "                for i, theme in enumerate(themes):\n",
    "                    st.write(f\"**Theme {i + 1}:** {theme}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
